\section{Introduction} \label{sec:introduction}

Development of hybrid and cyber-physical systems (CPS) is becoming
increasingly challenging as the designs for modern CPS become more and
more complex.  As these systems are found in many safety-critical
applications, like aircraft, medical devices, and automobiles, it is
vital that they behave in a manner consistent with their
design expectations. Despite this, it is difficult to verify that CPS
designs meet their requirements for complex applications.

% We address this challenge by presenting a new method to automatically
% identify incorrect system behaviors.  Our method searches for faulty
% system behaviors using a metaheuristic falsification approach, which
% leverages a combination of existing search techniques.  The technique
% uses notions of behavior robustness, with respect to requirements, in
% combination with notions of coverage of the search space, to improve
% the overall search performance.

Property \emph{falsification} has garnered much interest recently as a
way to perform automatic bug-finding for complex CPS design
models. Many falsification techniques rely on a requirement
provided in a specification language such as temporal logic.
Two such
languages that are appropriate for CPS applications are metric
temporal logic (MTL) and signal temporal logic (STL)
\cite{Koymans1990,MalerN04}, which are used to specify behaviors defined
using real-valued signals over dense time. A key feature of MTL and
STL is that they are equipped with \emph{robust} semantics, and for a given behavior, methods exist to efficiently compute a
real value, called the robustness, which indicates how well the
behavior does or does not satisfy the requirement
\cite{FainekosP06fates,DonzeM10}. A positive robustness value
indicates the behavior satisfies the requirement; a negative
robustness value indicates the behavior does not satisfy the
requirement. Falsification procedures use the robustness as the objective function
for a global optimizer, which seeks a
behavior with negative robustness value. Thus, the optimizer can
be used to automatically find behaviors that violate (falsify) the
requirement. Falsification techniques have been applied to many CPS
systems and are finding application in industry, using tools like
S-TaLiRo and Breach \cite{TaliroLFS11,BreachCAV10}.

One challenge in falsification for CPS is that it often
involves optimization over continuous-time input signals, which are of infinite 
dimension, whereas existing optimization solvers expect a finite number of 
dimensions. 
A typical approach, such as the ones taken in \cite{BreachCAV10} and 
\cite{Nghiem10}, is to consider input signals spaces that can be described using a
finite number of bounded parameters. For example, we consider the family of
piecewise constant signals with discontinuities occurring at a finite number of fixed time instants, where the
constant values between discontinuities are the decision variables for the optimization
problem. One drawback of using this type of fixed time parameterization 
is that the falsification performance depends on the selection of the fixed time instants, 
which is often based largely on intuition. Another drawback is that, for cases where the
inputs must satisfy non-trivial constraints, encoding these constraints 
into bounded domains for parameters can be difficult. Little attention has
been given to these considerations in the literature, though in 
\cite{DBLP:conf/atva/DeshmukhJKM15} the authors proposed a
falsification strategy featuring variable time discretizations.

In addition to the problem of encoding input signal spaces, coverage is an important consideration in testing for CPS, though it can be 
difficult to define and measure.
One challenge is in defining meaningful coverage measures that apply to continuous
variables and continuous-time signals. When the input signal space is paramterized, the coverage can be defined on the parameter space. 
Measures like \emph{dispersion} try to capture the size of the empty space between points that have been explored \cite{Esposito04}.
A related and simple measure, partitions the search space into cells and measures the proportion of cells that are occupied by explored points \cite{Skruch2011}.
This method is related to the combinatorial entropy notion from the domain of physics to measure the degree of randomness in a distribution of points \cite{Gabbay06}.
The \emph{star discrepancy} measure was developed by the statistical community 
to measure the degree to which a set of points are equidistributed
\cite{Heinrich03}. 
Coverage measures like these can be used to make decisions regarding the search strategy, and they were used in this way to develop CPS falsification and test generation methods that attempt to maximize the coverage of the search space \cite{DangN09,Dreossi2015,CAV2017}. Search methods like these are capable of reporting the coverage to the user, which is helpful to understand how much confidence 
can be placed in the result when no falsifying behavior is found (i.e., the coverage level can indicate \emph{how well} the system was tested). 

One challenge with search methods that rely on coverage measures  is that they are compatible with convex constraints on the variables, such as range limits, 
but they are difficult to apply to systems with complex variable constraints, such as constraints with temporal components.
To address this, we provide an novel coverage-based search approach that is compatible with input signals with temporal constraints. Our method converts the constraints to 
timed automata and then uses coverage metrics defined for the automata.
This allows our falsification framework to target coverage of the specifications as well as of the system behaviors.
Our approach dynamically adjusts input signal parameterization to achieve
efficient coverage of the input signal space subject to
the temporal constraints. Our approach builds on uniform
distributions of traces of timed automata presented in \cite{}.
\alex{needs check and citation here}.


%Another core idea is that, given a collection of traditional search
%algorithms, we can judiciously switch between algorithms online, if we
%consider the evolution of both the robustness values and the coverage
%of the search space.


%We introduce a new metaheuristic approach to the search
%problem, which uses measures of both robustness and coverage to make
%decisions about how best to guide the search.
Another crucial factor in the performance of falsification techniques is the efficacy of the global optimization process.
Global optimization algorithms can be broadly classified into one of two
categories: exploration-based and exploitation-based \cite{Blum03}.
Exploration-based methods evaluate points from a widely distributed area 
of the search space, to identify regions that are most promising with 
respect to the cost function. Exploitation-based methods, on the other hand, 
use estimates of the shape of the cost function surface, often locally, to
identify a candidate direction that is most likely to yield a decrease
in cost.  Each type of method has strengths and weaknesses. Exploration
methods are not in danger of getting trapped in local minima, but they may 
be inefficient in terms of identifying appropriate directions to search.  By
contrast, exploitation methods are designed to efficiently identify
promising local search directions, but they can get trapped in local optima.
We present a method that synergizes exploration and 
exploitation by adaptively switching between the two strategies.
The tradeoffs between exploitation and exploration have been explored by others, 
for the purposes of falsification for CPS \cite{Ratschan14}. We present a falsification framework that goes further, by incorporating coverage and robustness together to decide when to change search methodology.

Our method is an iterative procedure that utilizes several 
\emph{metaheuristics}, which are search methods that can be applied to
a wide variety of problem classes.\footnote{In contrast to metaheuristics, \emph{heuristic} methods are 
designed for specific classes of problems.} Examples include: Simulated Annealing and pseudo-random search. Our method can be described as follows. 
In each iteration, our
search procedure considers the evolution of both the best-case
robustness value (the optimization cost) as well as the evolution of a
coverage measure.  We use the information to make online decisions
about when and how to switch from one optimization strategy to
another.  For example, if we are using an exploitation-driven method,
and we decide that the decrease in robustness has ``stalled" (is not
decreasing quickly) and the coverage is ``low", we will switch from
the exploitation-driven method to an alternative exploration-driven
method.  If, alternatively, we are using an exploration-driven method,
and we decide that the coverage is relatively ``high" and the
robustness is near zero, then we will switch to an exploitation-driven
method, using the current best point as an initial condition.
 
Our falsification framework can outperform existing methods with little user intervention or reliance on intuition. We demonstrate this on several 
challenging CPS examples.


%Some of these metaheuristics are
%characterized as exploration-driven methods because of their
%capability of generating diverse candidate solutions. In an opposing
%direction, some are characterized as exploitation-driven methods
%because of their capability of quicky find better solutions in the
%neighborhood of initial candidate solutions.


% We demonstrate the efficacy of our approach on several challenging
% examples, including an automotive transmission model, a diesel
% engine control model, and a model of a hydrogen fuel cell air
% control system.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
